input {
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["ci_raw_lines"]
    group_id => "logstash-ci-raw"
    auto_offset_reset => "latest"
    codec => json
  }
}

filter {
  # -----------------------
  # Stable file id
  # -----------------------
  if [file_id] {
    mutate { copy => { "file_id" => "[@metadata][file_id]" } }
  } else {
    mutate { add_field => { "[@metadata][file_id]" => "%{day_folder}/%{filename}" } }
  }

  # -----------------------
  # FILE START: init state
  # -----------------------
  if [event_type] == "file_start" {
    aggregate {
      task_id => "%{[@metadata][file_id]}"
      code => "
        map['day_folder'] = event.get('day_folder')
        map['filename'] = event.get('filename')
        map['path'] = event.get('path')
        map['builder'] = nil
        map['slave'] = nil
        map['buildid'] = nil
        map['builduid'] = nil
        map['revision'] = nil
        map['result_status'] = nil
        map['result_code'] = nil
        map['starttime_epoch'] = nil
        map['current_step'] = nil
      "
    }
    drop {}
  }

  # -----------------------
  # RAW LINE: parse
  # -----------------------
  if [event_type] == "raw_line" {

    # Header patterns
    grok {
      match => {
        "message" => [
          "^builder:\s+%{GREEDYDATA:hdr_builder}$",
          "^slave:\s+%{GREEDYDATA:hdr_slave}$",
          "^starttime:\s+%{NUMBER:hdr_starttime:float}$",
          "^buildid:\s+%{GREEDYDATA:hdr_buildid}$",
          "^builduid:\s+%{GREEDYDATA:hdr_builduid}$",
          "^revision:\s+%{GREEDYDATA:hdr_revision}$",
          "^results:\s+%{WORD:hdr_result_status}\s+\(%{NUMBER:hdr_result_code:int}\)$"
        ]
      }
      tag_on_failure => []
    }

    # Store headers in state
    if [hdr_builder] or [hdr_slave] or [hdr_starttime] or [hdr_buildid] or [hdr_builduid] or [hdr_revision] or [hdr_result_status] {
      aggregate {
        task_id => "%{[@metadata][file_id]}"
        code => "
          if event.get('hdr_builder'); map['builder']=event.get('hdr_builder'); end
          if event.get('hdr_slave'); map['slave']=event.get('hdr_slave'); end
          if event.get('hdr_starttime'); map['starttime_epoch']=event.get('hdr_starttime'); end
          if event.get('hdr_buildid'); map['buildid']=event.get('hdr_buildid'); end
          if event.get('hdr_builduid'); map['builduid']=event.get('hdr_builduid'); end
          if event.get('hdr_revision'); map['revision']=event.get('hdr_revision'); end
          if event.get('hdr_result_status'); map['result_status']=event.get('hdr_result_status').downcase; end
          if event.get('hdr_result_code') != nil; map['result_code']=event.get('hdr_result_code'); end
        "
      }
      drop {}   # donâ€™t index header lines as events
    }

    # Step start/end
    grok {
      match => {
        "message" => [
          "^=+ Started %{GREEDYDATA:step_name} \\(results:\\s*%{NUMBER:step_result:int}, elapsed:\\s*%{GREEDYDATA:step_elapsed_text}\\) \\(at %{GREEDYDATA:step_at}\\) =+$",
          "^=+ Finished %{GREEDYDATA:step_name} \\(results:\\s*%{NUMBER:step_result:int}, elapsed:\\s*%{GREEDYDATA:step_elapsed_text}\\) \\(at %{GREEDYDATA:step_at}\\) =+$"
        ]
      }
      tag_on_failure => []
    }

    if [step_name] and [message] =~ /^=+ Started / {
      mutate { replace => { "record_type" => "step_start" } }
      aggregate { task_id => "%{[@metadata][file_id]}" code => "map['current_step']=event.get('step_name')" }
    } else if [step_name] and [message] =~ /^=+ Finished / {
      mutate { replace => { "record_type" => "step_end" } }
      aggregate { task_id => "%{[@metadata][file_id]}" code => "map['current_step']=nil" }
    }

    # Exit/elapsedTime inside steps
    grok {
      match => {
        "message" => [
          "program finished with exit code %{NUMBER:exit_code:int}",
          "elapsedTime=%{NUMBER:elapsedTime:float}"
        ]
      }
      tag_on_failure => []
    }
    if [exit_code] or [elapsedTime] {
      mutate { add_field => { "record_type" => "step_signal" } }
    }

    # Runtime severity lines: "16:37:15 INFO - blah"
    grok {
      match => { "message" => "^%{TIME:log_time}\s+%{WORD:severity}\s+-\s+%{GREEDYDATA:log_msg}$" }
      tag_on_failure => []
    }
    if [log_msg] {
      mutate {
        replace => { "record_type" => "log_line" }
        rename => { "log_msg" => "message" }
        uppercase => ["severity"]
      }
    }

    # Default: keep as text_line
    if ![record_type] {
      mutate { add_field => { "record_type" => "text_line" } }
    }

    # Attach state to every event (join keys)
    aggregate {
      task_id => "%{[@metadata][file_id]}"
      code => "
        event.set('day_folder', map['day_folder'])
        event.set('filename', map['filename'])
        event.set('path', map['path'])
        event.set('builder', map['builder'])
        event.set('slave', map['slave'])
        event.set('buildid', map['buildid'])
        event.set('builduid', map['builduid'])
        event.set('revision', map['revision'])
        event.set('result_status', map['result_status'])
        event.set('result_code', map['result_code'])
        event.set('starttime_epoch', map['starttime_epoch'])
        event.set('current_step', map['current_step'])
      "
    }

    mutate {
      remove_field => [
        "event_type","ts_ingest",
        "hdr_builder","hdr_slave","hdr_starttime","hdr_buildid","hdr_builduid","hdr_revision","hdr_result_status","hdr_result_code"
      ]
    }
  }

  # -----------------------
  # FILE END: emit job doc
  # -----------------------
  if [event_type] == "file_end" {
    aggregate {
      task_id => "%{[@metadata][file_id]}"
      end_of_task => true
      code => "
        event.set('record_type', 'job_header')
        event.set('day_folder', map['day_folder'])
        event.set('filename', map['filename'])
        event.set('path', map['path'])
        event.set('builder', map['builder'])
        event.set('slave', map['slave'])
        event.set('buildid', map['buildid'])
        event.set('builduid', map['builduid'])
        event.set('revision', map['revision'])
        event.set('result_status', map['result_status'])
        event.set('result_code', map['result_code'])
        event.set('starttime_epoch', map['starttime_epoch'])
      "
    }
    mutate { remove_field => ["event_type","ts_ingest","lines_sent"] }
  }

  # ============================================================
  # FINAL: compute index date from day_folder AND set @timestamp
  # ============================================================
  if [day_folder] {
    grok {
      match => { "day_folder" => "^log-%{YEAR:yyyy}-%{MONTHNUM:mm}-%{MONTHDAY:dd}$" }
      tag_on_failure => []
    }
    if [yyyy] and [mm] and [dd] {
      mutate { add_field => { "[@metadata][index_date]" => "%{yyyy}.%{mm}.%{dd}" } }

      mutate { add_field => { "folder_date" => "%{yyyy}-%{mm}-%{dd}T00:00:00Z" } }
      date { match => ["folder_date", "ISO8601"] target => "@timestamp" }

      mutate { remove_field => ["yyyy","mm","dd","folder_date"] }
    }
  }
}

output {
  if [record_type] == "job_header" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "ci-jobs-%{[@metadata][index_date]}"
    }
  } else {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "ci-events-%{[@metadata][index_date]}"
    }
  }
}
